---
title: "Correction to Stahl, Klauer, & Erdfelder (2008) 'Matching bias in the selection task is not eliminated by explicit negations'"
author:
  - name: Christoph Stahl
    address: Herbert-Lewin-Str. 2, D-50931 Cologne, Germany
    affiliation: '1'
    corresponding: yes
    email: christoph.stahl@uni-koeln.de
  - name: Karl Christoph Klauer
    affiliation: '2'
  - name: Edgar Erdfelder
    affiliation: '3'
affiliation:
  - id: '1'
    institution: University of Cologne
  - id: '2'
    institution: University of Freiburg
  - id: '3'
    institution: University of Mannheim
author_note: |
  Christoph Stahl, Department of Psychology. Karl Christoph Klauer, Institute for Psychology. Edgar Erdfelder, Department of Psychology, School of Social Sciences. 

  We are grateful to Phil Johnson-Laird for bringing the discrepancies in the reported results to our attention.
output: papaja::apa6_pdf
keep_md: yes
keep_tex: yes
class: man
figsintext: yes
figurelist: no
footnotelist: no
lang: english
lineno: no
bibliography: [references/r-references.bib, references/methexp.bib]
shorttitle: Correction to Stahl, Klauer, & Erdfelder (2008)
tablelist: no
abstract: |
  This document reproduces the analyses and corrects the results reported in @stahl_matching_2008.  There were some reporting errors in the article (due to use of an incorrect data file version) that are corrected below.  The corrections affect neither the pattern of results discussed nor the conclusions drawn in the article.  First, the corrections are given in a compression fashion.  For the reader's convenience, those sections of the paper for which any corrections were made are then reprinted below.  Raw data and additional material can be obtained at http://osf.io/q5ssw.
---

```{r init, include = FALSE}
library("papaja")
library(MPTinR)
library(snowfall)
source("model_files/mptinr_tools.R")
```



```{r exp1, echo=FALSE}

#### load and prepare ####

e1 <- read.table("exp1.dat", col.names=c("bed", "lang", "letters", "p", "np", "q", "nq"
                                         , "aufgabe", "logic", "gender", "age", "occ"
                                         , "schooly", "field", "sprache", "serious"
                                         , "year", "month", "day", "hour", "min", "sec", "ip"))
e1$bed <- e1$bed-2

# apply exclusion criteria
e1 <- subset(e1, sprache<5 & serious==1 & aufgabe==0 & age<90 & lang!='null')
e1 <- e1[1:1326,]

# N per condition
ns1 <- table(e1$bed)
chisq1 <- chisq.test(ns1)

# logical status
e1$ta <- ifelse(e1$bed %in% c(1,2), e1$p, e1$np)
e1$fa <- ifelse(e1$bed %in% c(1,2), e1$np, e1$p)
e1$tc <- ifelse(e1$bed %in% c(1,3), e1$q, e1$nq)
e1$fc <- ifelse(e1$bed %in% c(1,3), e1$nq, e1$q)

#### indices ####

e1$li <- with(e1, (ta+fc)-(fa+tc))
e1$ami <- with(e1, p-np)
e1$cmi <- with(e1, q-nq)

ind <- aggregate(cbind(li,ami,cmi)~bed, data=e1, FUN=mean)

# AMI > 0?
e1.ami.t <- t.test(e1$ami)

# CMI > 0?
e1.cmi.t <- t.test(e1$cmi)

# LI > 0?
e1.li.t <- t.test(e1$li)

#### frequencies ####

# selection of 16 logical patterns
e1$pattern <- apply(X=e1, MARGIN = 1, FUN = function(x) paste0(x[24:27], collapse=""))
patfreq <- table(e1$pattern, e1$bed)
e1.tpf <- tpf <- t(patfreq)

# selection of four logical cases
cardfreq <- matrix(0, nrow = 4, ncol = 4)
colnames(cardfreq) <- c("ta","fa","tc","fc")
cardfreq[,1] <- apply(tpf, 1, FUN=function(x)sum(x[9:16]))
cardfreq[,2] <- apply(tpf, 1, FUN=function(x)sum(x[c(5:8,13:16)]))
cardfreq[,3] <- apply(tpf, 1, FUN=function(x)sum(x[c(3:4,7:8,11:12,15:16)]))
cardfreq[,4] <- apply(tpf, 1, FUN=function(x)sum(x[c(2,4,6,8,10,12,14,16)]))
e1.cardfreq <- cardfreq

# prepare freq for modeling
mbt1 <- c(tpf[1,],tpf[2,],tpf[3,],tpf[4,]) 
mbt1 <- cbind(catno=1:64, freq=mbt1+1) # add 1 to account for zero cell
write.table(mbt1, file = "model_files/exp1_p1.mdt", row.names = FALSE, quote = FALSE)
write(x="===",file="model_files/exp1_p1.mdt", append = TRUE)



```





```{r exp2, echo=FALSE}

#### load and prepare ####
e2 <- read.table("exp2.dat", col.names=c("bed", "lang", "letters", "ta", "fa", "tc", "fc"
                                         , "aufgabe", "logic", "gender", "age", "occ"
                                         , "schooly", "field", "sprache", "serious", "year"
                                         , "month", "day", "hour", "min", "sec", "ip", "order"))
e2$neg <- (e2$bed-1) %/% 4

# apply exclusion criteria
e2 <- subset(e2, sprache<5 & serious==1 & aufgabe==0 & age<90 & lang!='null')
e2 <- e2[1:2661,] # collect data until the last condition has a minimum of n=300

# N per condition
ns2 <- table(e2$bed)
chisq2 <- chisq.test(ns2)

#### indices ####

e2$li <- with(e2, (ta+fc)-(fa+tc))
e2$ami <- ifelse(e2$bed %in% c(1,2,5,6), e2$ta-e2$fa, e2$fa-e2$ta)
e2$cmi <- ifelse(e2$bed %in% c(1,3,5,7), e2$tc-e2$fc, e2$fc-e2$tc)

ind2 <- aggregate(cbind(li,ami,cmi)~bed, data=e2, FUN=mean)
ind2$neg <- (ind2$bed-1) %/% 4
ind2m <- aggregate(cbind(li,ami,cmi)~neg, data=ind2, FUN=mean)

im2 <- subset(e2, bed<=4)
ex2 <- subset(e2, bed>4)

# implicit negation, AMI > 0?
e2.ami.ti <- t.test(im2$ami)

# implicit negation, CMI > 0?
e2.cmi.ti <- t.test(im2$cmi)

# implicit negation, LI > 0?
e2.li.ti <- t.test(im2$li)

# explicit negation, AMI > 0?
e2.ami.te <- t.test(ex2$ami)

# explicit negation, CMI > 0?
e2.cmi.te <- t.test(ex2$cmi)

# explicit negation, LI > 0?
e2.li.te <- t.test(ex2$li)

# differences: ami
e2.ami.td <- t.test(ami~neg, data=e2, var.equal=TRUE)

# differences: cmi
e2.cmi.td <- t.test(cmi~neg, data=e2, var.equal=TRUE)

# differences: li
e2.li.td <- t.test(li~neg, data=e2, var.equal=TRUE)

#### frequencies ####

# selection of 16 logical patterns
e2$pattern <- apply(X=e2, MARGIN = 1, FUN = function(x) paste0(x[4:7], collapse=""))
patfreq2 <- table(e2$pattern, e2$bed)
e2.tpf <- tpf <- t(patfreq2)

# selection of four logical cases
cardfreq <- matrix(0, nrow = 8, ncol = 4)
colnames(cardfreq) <- c("ta","fa","tc","fc")
cardfreq[,1] <- apply(tpf, 1, FUN=function(x)sum(x[9:16]))
cardfreq[,2] <- apply(tpf, 1, FUN=function(x)sum(x[c(5:8,13:16)]))
cardfreq[,3] <- apply(tpf, 1, FUN=function(x)sum(x[c(3:4,7:8,11:12,15:16)]))
cardfreq[,4] <- apply(tpf, 1, FUN=function(x)sum(x[c(2,4,6,8,10,12,14,16)]))
e2.cardfreq <- cardfreq

# prepare freq for modeling
mbt2i <- c(e2.tpf[1,],e2.tpf[2,],e2.tpf[3,],e2.tpf[4,])
mbt2i <- cbind(catno=1:64, freq=mbt2i+1) # add 1 to correct for zero cells
write.table(mbt2i, file = "model_files/exp2_im_p1.mdt", row.names = FALSE, quote = FALSE)
write(x="===",file="model_files/exp2_im_p1.mdt", append = TRUE)

mbt2e <- c(e2.tpf[5,],e2.tpf[6,],e2.tpf[7,],e2.tpf[8,])
mbt2e <- cbind(catno=1:64, freq=mbt2e+1) # add 1 to correct for zero cells
write.table(mbt2e, file = "model_files/exp2_ex_p1.mdt", row.names = FALSE, quote = FALSE)
write(x="===",file="model_files/exp2_ex_p1.mdt", append = TRUE)

```



```{r effect_sizes, echo=FALSE}
dami <- round(lsr::cohensD(ex2$ami), 2)
Nami <- pwr::pwr.t.test(d=dami, sig.level=.05, power=.8, alternative="greater", type="one.sample")
pwrami <- pwr::pwr.t.test(n=32, d=dami, sig.level=.05, alternative="greater", type="one.sample")
dcmi <- round(lsr::cohensD(ex2$cmi), 2)
Ncmi <- pwr::pwr.t.test(d=dcmi, sig.level=.05, power=.8, alternative="greater", type="one.sample")
pwrcmi <- pwr::pwr.t.test(n=32, d=dcmi, sig.level=.05, alternative="greater", type="one.sample")

```


```{r remodel, echo=FALSE}

# snowfall::sfInit(parallel=TRUE, cpus = 4)

#### fit models and save results
# e1fit <- fit_mpt(eqnfile = "model_files/WST_IGrelaxnegtest_negationpar.eqn", mdtfile = "model_files/exp1_p1.mdt" , restrictions = c("n_1=0"), n.optim=10, output="full", multicore="n.optim")
# save(e1fit, file="model_files/e1fit.RData")
# e2ifit <- fit_mpt(eqnfile = "model_files/WST_IGrelaxnegtest_negationpar.eqn", mdtfile = "model_files/exp2_im_p1.mdt", restrictions = c("n_1=0", "c_2=c_3")
#                   , n.optim=10, output="full", multicore="n.optim")
# save(e2ifit, file="model_files/e2ifit.RData")
# e2efit <- fit_mpt(eqnfile = "model_files/WST_IGrelaxnegtest_negationpar.eqn", mdtfile = "model_files/exp2_ex_p1.mdt", restrictions = c("c_1=c_4", "c_2=c_3")
#                   , n.optim=10, output="full", multicore="n.optim")
# save(e2efit, file="model_files/e2efit.RData")
# snowfall::sfStop()

#### load and display results
load("model_files/e1fit.RData")
load("model_files/e2ifit.RData")
load("model_files/e2efit.RData")

condnames=c("A3", "An3", "nA3", "nAn3")
parorder=c("p","np","q","nq","a","c","x","d","sl","sn","sln","i","n")

e1.res <- make.resulttable(e1fit, 4, condnames, parorder)
e2i.res <- make.resulttable(e2ifit, 4, condnames, parorder)
e2e.res <- make.resulttable(e2efit, 4, condnames, parorder)

print_table_line <- function(tbl=e1.res["a",]){
  # one row, four columns
  tbl <- as.character(tbl)
  out <- paste0(tbl[1], ", ", tbl[2], ", ", tbl[3], ", ", tbl[4])
  return(out)
}

```

There were some reporting errors in @stahl_matching_2008 that were due to use of an incorrect data file version in the original analyses.
They are corrected below.
The corrections affect neither the pattern of results discussed nor the conclusions drawn in the article.
Raw data and additional material can be obtained at http://osf.io/q5ssw.
^[The present analyses used `r papaja::cite_r(file="references/r-references.bib")`.]

The correct number of participants in the 8 groups of Experiment 2 is `r ns2` (p. 288).
In Table 1 (p. 291), the correct values for AMI, CMI, and LI for Experiment 2 are 
`r round(mean(ind2m[1,]$ami), 2)`,
`r round(mean(ind2m[1,]$cmi), 2)`, and
`r round(mean(ind2m[1,]$li), 2)` for the implicit-negation condition, as well as
`r round(mean(ind2m[2,]$ami), 2)`,
`r round(mean(ind2m[2,]$cmi), 2)`, and
`r round(mean(ind2m[2,]$li), 2)` for the explicit-negation condition (and the correct values of the rescaled indices discussed on p. 295 are therefore `r 4*round(mean(ind2m[1,]$ami), 2)` and `r 4*round(mean(ind2m[1,]$cmi), 2)`).
The correct statistics for the $t$-tests against zero for these indices (reported on p. 292) are: 
`r round(c(e2.ami.ti$statistic, e2.cmi.ti$statistic, e2.li.ti$statistic),2)` (df=`r e2.ami.ti$parameter`, all $ps<.001$) 
for the implicit-negation condition; and
`r round(c(e2.ami.te$statistic, e2.cmi.te$statistic, e2.li.te$statistic),2)` (df=`r e2.ami.te$parameter`, all $ps<.01$) 
for the explicit-negation condition.
The correct statistics for the difference between implicit and explicit conditions are,
for the AMI, $t=`r round(c(e2.ami.td$statistic),2)`$, $p = .001$;
for the CMI, $t=`r round(c(e2.cmi.td$statistic),2)`$, $p < .001$;
and for the LI, $t=`r round(c(e2.li.td$statistic),2)`$, $p = .106$ 
($df = `r e2.ami.td$parameter`$).
The correct effect sizes for AMI and CMI (discussed on p. 295) are $d = `r dami`$ and $d = `r dcmi`$, 
which (assuming $\alpha=.05$ and $\beta=.80$) require samples sizes of $`r round(Nami$n, 0)`$ and $`r round(Ncmi$n, 0)`$ for detection; given $N=32$ and $\alpha=.05$, these effect sizes can be detected with negligible power (`r round(pwrami$power,2)` and `r round(pwrcmi$power,2)`).
In Table A2 (Appendix), the correct estimates (and 95% CIs) for parameter $a$ in Experiment 1 are (for conditions A3, An3, nA3, nAn3, respectively): `r print_table_line(e1.res["a",])`;
and the correct estimates for parameter $sn$ in the explicit-negation groups of Experiment 2 are: `r print_table_line(e2e.res["sn",])`.
None of the above corrections affected the article's substantive conclusions.


# Corrected sections of the paper

## Section "Participants" (p. 288)

Participants were sampled via the Internet. 
In Experiment 1 mean age was $M = `r round(mean(e1$age), 2)`$ years,
`r round(100*mean(e1$gender),0)`% of participants were male, 
and `r round(100*table(e1$lang)[2]/length(e1$lang),0)`% participated in the German version. 
In Experiment 2 mean age was $M = `r round(mean(e2$age), 2)`$ years, 
`r round(100*mean(e2$gender),0)`% of participants were male, 
and `r round(100*table(e2$lang)[2]/length(e2$lang),0)`% participated in the German version. 
In Experiment 1 there were `r ns1` <!--336, 300, 341, and 349--> participants in the groups labelled A3, An3, nA3, and nAn3, respectively. 
In Experiment 2 there were `r ns2` <!--360, 332, 329, 321, 346, 300, 205, and 323--> participants in the groups labelled IA3, IAn3, InA3, InAn3, EA3, EAn3, EnA3, and EnAn3, respectively.

## Section "Results" (p. 290)

To assess the possibility of selective dropout, we tested as a first step whether the numbers of accepted submissions were significantly different between the experimental groups. 
The number of participants did not differ significantly between the different experimental groups in each experiment, 
`r apa.g2(q=chisq1$statistic, df=chisq1$parameter, p=chisq1$p.value)`, 
and `r apa.g2(q=chisq2$statistic, df=chisq2$parameter, p=chisq2$p.value)`
 for Experiment 1 and 2, respectively.
[...]

## Table 1 (p. 291)

In Table 1, the correct values for AMI, CMI, and LI for Experiment 2 are 
`r round(mean(ind2m[1,]$ami), 2)`,
`r round(mean(ind2m[1,]$cmi), 2)`, and
`r round(mean(ind2m[1,]$li), 2)` for the implicit-negation condition, as well as
`r round(mean(ind2m[2,]$ami), 2)`,
`r round(mean(ind2m[2,]$cmi), 2)`, and
`r round(mean(ind2m[2,]$li), 2)` for the explicit-negation condition.

## Section "Matching and logic indices" (last paragraph, p. 292)

In the implicit groups in Experiment 2, as expected, the AMI, CMI, and LI were significantly larger than zero <!--(t ¼ 8.11, 14.62, and 13.54, respectively, df ¼ 1341, all ps 5 .001).--> 
($t = `r round(c(e2.ami.ti$statistic, e2.cmi.ti$statistic, e2.li.ti$statistic),2)`$, $df=`r e2.ami.ti$parameter`$, all $ps<.001$).
Importantly, and in contrast to the findings reported by Evans et al. (1996), the indices were also significantly larger than zero in the explicit groups 
<!--todo: (t ¼ 5.14, 7.90, and 10.30, respectively, df ¼ 1273, all ps 5 .001).--> 
($t = `r round(c(e2.ami.te$statistic, e2.cmi.te$statistic, e2.li.te$statistic),2)`$, $df=`r e2.ami.te$parameter`$, all $ps<.01$).
The differences between implicit and explicit groups in the AMI and the CMI (but not the LI) were significant:
<!--and the LI were significant: for the difference in the AMI, t ¼ 2.08, p ¼ .04; in the CMI, t ¼ 4.00, p5 .01; in the LI, t ¼ 2.09, p ¼ .04 (df ¼ 2614).-->
for the difference in the AMI, $t=`r round(c(e2.ami.td$statistic),2)`$, $p = .001$;
in the CMI, $t=`r round(c(e2.cmi.td$statistic),2)`$, $p < .001$;
in the LI, $t=`r round(c(e2.li.td$statistic),2)`$, $p = .106$ 
($df = `r e2.ami.td$parameter`$).


## Section "Discussion" (p. 294f)

When the present indices are rescaled to range between -4 and +4, an AMI value of `r 4*round(mean(ind$ami), 2)` results for Experiment 1, and of `r 4*round(mean(ind2m[1,]$ami), 2)` for the implicit groups of Experiment 2, which is comparable to the value of 0.73 that was obtained by Evans et al. (1995, Exp.3); 
similarly, the rescaled CMI values were `r 4*round(mean(ind$cmi),2)` and `r 4*round(mean(ind2m[1,]$cmi), 2)` for Experiment 1 and the implicit groups from Experiment 2, respectively, which is of comparable magnitude to the value of 1.33 obtained by Evans et al. (1995, Exp.3).

## Section "Discussion" (p. 295, effect sizes and power analyses)

In the explicit negation conditions of the present Experiment 2, the AMI effect was small, $d = `r dami`$. 
To obtain an effect of this magnitude with $\alpha = .05$ and a power of at least $1 - \beta = .80$, a sample size of  $`r round(Nami$n, 0)`$  is required. 
Given the $N = 32$ reported by Evans et al. (1995) for the explicit conditions, the power to detect an effect of  $d = `r dami`$  was only  `r round(pwrami$power,2)`. 
Similarly, in the explicit negation conditions of the present Experiment 2, the CMI effect was small, $d = `r dcmi`$; 
to obtain such an effect $\alpha = .05$ and a power of at least $1 - \beta = .80$, a sample size of $`r round(Ncmi$n,0)`$ is required; 
and given the $N = 32$ reported by Evans et al. (1995) for the explicit conditions, the power to detect an effect of $d = `r dcmi`$ was only `r round(pwrcmi$power,2)`. 
We conclude that the residual matching effects in the explicit conditions of the present Experiment 2 were small (cf. Cohen, 1988);
in fact, they were too small to be detected in a small sample of $N = 32$, in which effects must be of at least medium size ($d >= .45$) to be detected with an acceptable power of at least $1 - \beta = .80$ (in a one-sample, one-sided $t$-test).


## Appendix, Table A2

The model's parameter estimates (reported in Table A2 of the article) are reproduced here in Table 1 (for Experiment 1), Table 2 (Experiment 2, implicit negation), and Table 3 (Experiment 2, explicit negation).

```{r results='asis'}
papaja::apa_table(e1.res, caption = "Experiment 1", note = "Estimates of parameter $a$ were corrected.")
```

```{r results='asis'}
papaja::apa_table(e2i.res, caption = "Experiment 2, implicit negation")
```

```{r results='asis'}
papaja::apa_table(e2e.res, caption = "Experiment 2, explicit negation", note = "Estimates of parameter $sn$ were corrected.")
```

\clearpage

# References
```{r create_r-references, echo=FALSE}
r_refs(file = "references/r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
